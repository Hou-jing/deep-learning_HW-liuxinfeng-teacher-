{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled54.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNdmIvtJCGcR",
        "outputId": "00dedc14-79b6-4c8a-d599-786b88dac808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-21 10:30:02--  https://www.dropbox.com/s/dleabirlq4o3klo/Dataset.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/dleabirlq4o3klo/Dataset.zip [following]\n",
            "--2022-05-21 10:30:02--  https://www.dropbox.com/s/raw/dleabirlq4o3klo/Dataset.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc734fb803905fb3bacb59c47387.dl.dropboxusercontent.com/cd/0/inline/BlpZruYK1dG48xZr5SMq0JtbfMhKQyjNXOCW60YNHFPf-MuqrjebbPRZWj63ZlC1tcHvWqRtY-niYz0D_6d9-qXyJLElBiso-gR3U3mFM5JgUpAtjVAOqi1uhVbFu7BfKrx8YXbiAOeeUNnu2oFDTeztXu_wzgDE11xENEOFEZ5vnA/file# [following]\n",
            "--2022-05-21 10:30:03--  https://uc734fb803905fb3bacb59c47387.dl.dropboxusercontent.com/cd/0/inline/BlpZruYK1dG48xZr5SMq0JtbfMhKQyjNXOCW60YNHFPf-MuqrjebbPRZWj63ZlC1tcHvWqRtY-niYz0D_6d9-qXyJLElBiso-gR3U3mFM5JgUpAtjVAOqi1uhVbFu7BfKrx8YXbiAOeeUNnu2oFDTeztXu_wzgDE11xENEOFEZ5vnA/file\n",
            "Resolving uc734fb803905fb3bacb59c47387.dl.dropboxusercontent.com (uc734fb803905fb3bacb59c47387.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc734fb803905fb3bacb59c47387.dl.dropboxusercontent.com (uc734fb803905fb3bacb59c47387.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BlqITthUivBII0SW1RLBzTo9YXsiv7GdI0_O60vDzwffevcTXRDMZ4Iyx8qAKk30T_9mTp-MICE7Q656jaQsAjIy-sP2LfHzpVm9BWMdwhNasP8P_TFf0RuL8WCFUzpGUFgNuAub4E1THwKsjDTI9Xw87E1TtdNbSwPWCZcgGv-p44BDfusLcQzJIhSJUu-Uy_EAofO3S_QCXCLB1yM0R3NsJciHeR0Fb1sp-XOaS1CRHFa5zYreEh7fl86hilYCU85-65R_MpKkY6C4Y3rm3az5rX4oV8WomEKgetf1fIR-Cwv4Wje6TBJZyUerF6Vv4tgQjZjfVyfy9g4aCVODJnO8-l7oJXySDJ2Ff3qNKfPVvCofxSo7VPtd51LY_04hbpcXJBzhV1mXbbPkmQgMK7ZKmXzIXvYbbqHhXBu3SQDgVA/file [following]\n",
            "--2022-05-21 10:30:03--  https://uc734fb803905fb3bacb59c47387.dl.dropboxusercontent.com/cd/0/inline2/BlqITthUivBII0SW1RLBzTo9YXsiv7GdI0_O60vDzwffevcTXRDMZ4Iyx8qAKk30T_9mTp-MICE7Q656jaQsAjIy-sP2LfHzpVm9BWMdwhNasP8P_TFf0RuL8WCFUzpGUFgNuAub4E1THwKsjDTI9Xw87E1TtdNbSwPWCZcgGv-p44BDfusLcQzJIhSJUu-Uy_EAofO3S_QCXCLB1yM0R3NsJciHeR0Fb1sp-XOaS1CRHFa5zYreEh7fl86hilYCU85-65R_MpKkY6C4Y3rm3az5rX4oV8WomEKgetf1fIR-Cwv4Wje6TBJZyUerF6Vv4tgQjZjfVyfy9g4aCVODJnO8-l7oJXySDJ2Ff3qNKfPVvCofxSo7VPtd51LY_04hbpcXJBzhV1mXbbPkmQgMK7ZKmXzIXvYbbqHhXBu3SQDgVA/file\n",
            "Reusing existing connection to uc734fb803905fb3bacb59c47387.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3304269 (3.2M) [application/zip]\n",
            "Saving to: ‘Dataset.zip’\n",
            "\n",
            "Dataset.zip         100%[===================>]   3.15M  9.69MB/s    in 0.3s    \n",
            "\n",
            "2022-05-21 10:30:04 (9.69 MB/s) - ‘Dataset.zip’ saved [3304269/3304269]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/dleabirlq4o3klo/Dataset.zip?dl=0  -O Dataset.zip\n",
        "!unzip -q Dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEdkKNlr5NwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a66cce2-c301-4a23-ef72-8034de33a6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 33.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIINx-b06Vrp"
      },
      "source": [
        "## load_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5d6aLJF6Te2"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "path = 'Dataset'\n",
        "def load_corpus(path):\n",
        "    \"\"\"\n",
        "    :param path: 样本语料库的文件\n",
        "    :return: 文本内容contents，以及分类标签labels(onehot形式)\n",
        "    \"\"\"\n",
        "    contents, labels = [], []\n",
        "    with open(path, encoding='utf-8') as f:\n",
        "        for line in f.readlines():\n",
        "            sp = line.strip().split()\n",
        "            if(len(sp) == 0):\n",
        "                continue\n",
        "            label = int(sp[0])\n",
        "            content =''.join(i for i in sp[1:])\n",
        "            labels.append(label)\n",
        "            contents.append(content)\n",
        "    counter = Counter(labels)\n",
        "    print('总样本数为：%d' % (len(labels)))\n",
        "    print('各个类别样本数如下：')\n",
        "    for w in counter:\n",
        "        print(w, counter[w])\n",
        "    return contents, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQiX9Z7i6az5"
      },
      "source": [
        "## data_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZCetWTN6apC",
        "outputId": "b853b6c6-8edd-4d08-d297-5586ac598572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "下载 BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "print('下载 BERT tokenizer...')\n",
        "BERT_MAX_LEN=128\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=True)\n",
        "class Datapro:\n",
        "    def __init__(self,sents):\n",
        "        self.sentences=sents\n",
        "\n",
        "    def datagen(self):\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "        for sent in self.sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = tokenizer(\n",
        "                sent,  # Sentence to encode.\n",
        "                add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "                max_length=128,  # Pad & truncate all sentences.\n",
        "                pad_to_max_length=True,\n",
        "                return_attention_mask=True,  # Construct attn. masks.\n",
        "                return_tensors='pt',  # Return pytorch tensors.\n",
        "            )\n",
        "\n",
        "            # 把编码的句子加入list.\n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "            # 加上 attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "        return input_ids,attention_masks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_VUxi0N6gYP"
      },
      "source": [
        "## 主函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBw8ZQwv6fzj",
        "outputId": "9883b227-8c99-41b3-d44d-94ee52803c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "总样本数为：19998\n",
            "各个类别样本数如下：\n",
            "1 9999\n",
            "0 9999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "总样本数为：5629\n",
            "各个类别样本数如下：\n",
            "1 2812\n",
            "0 2817\n",
            "原句:  死囚爱刽子手女贼爱衙役我们爱你们难道还有别的选择没想到胡军除了蓝宇还有东宫西宫我个去阿兰这样真他nia恶心爱个P分明只是欲\n",
            "Token IDs: tensor([  101,  3647,  1723,  4263,  1175,  2094,  2797,  1957,  6592,  4263,\n",
            "         6126,  2514,  2769,   812,  4263,   872,   812,  7410,  6887,  6820,\n",
            "         3300,  1166,  4638,  6848,  2885,  3766,  2682,  1168,  5529,  1092,\n",
            "         7370,   749,  5905,  2126,  6820,  3300,   691,  2151,  6205,  2151,\n",
            "         2769,   702,  1343,  7350,  1065,  6821,  3416,  4696,   800, 10560,\n",
            "         8139,  2626,  2552,  4263,   702,   158,  1146,  3209,  1372,  3221,\n",
            "         3617,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "attention_masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "原句:  台湾导演执导林志玲一人分饰两角扮演一对双胞胎姐妹廖凡陈坤杨佑宁出演豆瓣评分分所以才看前半部分不算太过分结尾太狗血受不了陈坤越来越像Gay脸色那么黄健康问题\n",
            "Token IDs: tensor([  101,  1378,  3968,  2193,  4028,  2809,  2193,  3360,  2562,  4386,\n",
            "          671,   782,  1146,  7652,   697,  6235,  2815,  4028,   671,  2190,\n",
            "         1352,  5528,  5522,  1995,  1987,  2445,  1127,  7357,  1787,  3342,\n",
            "          859,  2123,  1139,  4028,  6486,  4480,  6397,  1146,  1146,  2792,\n",
            "          809,  2798,  4692,  1184,  1288,  6956,  1146,   679,  5050,  1922,\n",
            "         6814,  1146,  5310,  2227,  1922,  4318,  6117,  1358,   679,   749,\n",
            "         7357,  1787,  6632,  3341,  6632,  1008, 12211,  5567,  5682,  6929,\n",
            "          720,  7942,   978,  2434,  7309,  7579,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "attention_masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    #训练数据\n",
        "    tcontents, tlabels = load_corpus(path + '/' + 'train.txt')\n",
        "    tinput_ids, tattention_masks=Datapro(tcontents).datagen()\n",
        "    #验证数据\n",
        "    vcontents, vlabels = load_corpus(path + '/' + 'validation.txt')\n",
        "    vinput_ids, vattention_masks = Datapro(vcontents).datagen()\n",
        "tinput_ids = torch.cat(tinput_ids, dim=0)\n",
        "tattention_masks = torch.cat(tattention_masks, dim=0)\n",
        "tlabels = torch.tensor(tlabels)\n",
        "print('原句: ', tcontents[0])\n",
        "print('Token IDs:', tinput_ids[0])\n",
        "print('attention_masks:', tattention_masks[0])\n",
        "#验证集\n",
        "vinput_ids = torch.cat(vinput_ids, dim=0)\n",
        "vattention_masks = torch.cat(vattention_masks, dim=0)\n",
        "vlabels = torch.tensor(vlabels)\n",
        "print('原句: ', vcontents[0])\n",
        "print('Token IDs:', vinput_ids[0])\n",
        "print('attention_masks:', vattention_masks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D0_n3qb-bLL"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n49JpEs1-dwE",
        "outputId": "7854223e-4144-4315-811c-8c0a67900417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19,998 训练数据\n",
            "5,629 验证数据\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# 把input 放入 TensorDataset。\n",
        "train_dataset = TensorDataset(tinput_ids, tattention_masks, tlabels)\n",
        "val_dataset = TensorDataset(vinput_ids, vattention_masks, vlabels)\n",
        "# 计算 train_size 和 val_size 的长度.\n",
        "train_size = int( len(train_dataset))\n",
        "val_size = int( len(val_dataset))\n",
        "\n",
        "print('{:>5,} 训练数据'.format(train_size))\n",
        "print('{:>5,} 验证数据'.format(val_size))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLCB5CLSOi05"
      },
      "source": [
        "## dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP3OPXIxJ-d1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# 推荐batch_size 为 16 或者 32\n",
        "batch_size = 32\n",
        "\n",
        "# 为训练数据集和验证数据集设计DataLoaders.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # 训练数据.\n",
        "            sampler = RandomSampler(train_dataset), # 打乱顺序\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # 验证数据.\n",
        "            sampler = RandomSampler(val_dataset), # 打乱顺序\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "from transformers import BertModel, BertConfig\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tffbgIuEOnsX"
      },
      "outputs": [],
      "source": [
        "def same_seeds(seed):\n",
        "    # torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    # np.random.seed(seed)\n",
        "    # random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "same_seeds(0)\n",
        "model_name='bert-base-chinese'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "LzKrlKCaIFR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "model_name = 'bert-base-chinese'"
      ],
      "metadata": {
        "id": "j81uuqJbIG6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bert_lstm(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Bert_lstm, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        self.lstm = nn.LSTM(input_size=768,hidden_size=768,batch_first=True)\n",
        "        self.dense1 = nn.Linear(768, 512)\n",
        "        self.dense2 = nn.Linear(512,128)\n",
        "        self.dense3 = nn.Linear(128,2)\n",
        "\n",
        "    def forward(self, input_ids,attention_mask):\n",
        "        output_bert = self.bert(input_ids,attention_mask)\n",
        "        output_lhs = output_bert.last_hidden_state\n",
        "        output_lstm, (output_hn, output_cn) = self.lstm(output_lhs)\n",
        "        output_dense1 = self.dense1(output_hn)\n",
        "        output_dense2 = self.dense2(output_dense1)\n",
        "        output = self.dense3(output_dense2)\n",
        "        return torch.squeeze(output)"
      ],
      "metadata": {
        "id": "Mfp_coCCu--y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh5GBKF7rO4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee561edb-a096-4359-f272-ed50ae1e2e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.nn import functional as F\n",
        "# bert 推荐 epochs 在2到4之间为好。\n",
        "epochs = 5\n",
        "\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "cri = nn.CrossEntropyLoss()\n",
        "mymodel = Bert_lstm()\n",
        "mymodel.to(device)\n",
        "optimizer = AdamW(mymodel.parameters(),\n",
        "                  lr = 1e-5 # args.learning_rate - 默认是 5e-5\n",
        "               \n",
        "                )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trainer"
      ],
      "metadata": {
        "id": "Z4XBH2iNIUEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sYQ-Dq26IkJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqDJZveLO2uF",
        "outputId": "6cde22e8-1b5e-4b4c-dbb9-00eb4ff65125"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "执行次数为：1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [08:46<00:00,  1.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.011382690639701626\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [08:51<00:00,  1.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.007500835387471176\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [08:51<00:00,  1.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00498590882009182\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [08:51<00:00,  1.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.003143255519509764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [08:51<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0020078781649831906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "def rtrain(rcnet):\n",
        "    i = 1\n",
        "    model_path = 'model'\n",
        "    print('执行次数为：{}'.format(i))\n",
        "    rcnet = rcnet.to(device)\n",
        "    rcnet.train()\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0\n",
        "        r_acc = 0\n",
        "        step = 0\n",
        "        for batch_idx, data in enumerate(tqdm(train_dataloader)):\n",
        "            torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "            inputs_id, att_mask,rel_batch = data\n",
        "            inputs_id, att_mask=inputs_id.to(device), att_mask.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # rc model识别关系  -----------------------------------------------------\n",
        "            rel_tar = rel_batch.to(device)\n",
        "\n",
        "            rel = rcnet(inputs_id, att_mask)  # 想得到的是B*len(label2id)\n",
        "\n",
        "            rel_loss=cri(rel,rel_tar)\n",
        "            t_loss =   rel_loss\n",
        "            t_loss.backward()\n",
        "\n",
        "            train_loss += t_loss.item()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "        print(train_loss/len(train_dataset))\n",
        "\n",
        "rtrain(mymodel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2A_2BSzmXcBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "aKSLqb6bIkwX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcLVMuMVRfAP"
      },
      "source": [
        "### 主函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scmykYNWRfAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06aefb9e-0ae7-4202-9cb6-95a842d44240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "总样本数为：369\n",
            "各个类别样本数如下：\n",
            "1 187\n",
            "0 182\n",
            "测试集 原句:  如果我无聊时网上乱逛偶尔看到这部电影我可能会给它打四星但是TNND姐是花大洋去电影院看姐在电影院睡着姐现在非常心疼电影票钱一部无聊至极电影\n",
            "Token IDs: tensor([ 101, 1963, 3362, 2769, 3187, 5464, 3198, 5381,  677,  744, 6859,  981,\n",
            "        2209, 4692, 1168, 6821, 6956, 4510, 2512, 2769, 1377, 5543,  833, 5314,\n",
            "        2124, 2802, 1724, 3215,  852, 3221,  162, 9502, 8168, 1995, 3221, 5709,\n",
            "        1920, 3817, 1343, 4510, 2512, 7368, 4692, 1995, 1762, 4510, 2512, 7368,\n",
            "        4717, 4708, 1995, 4385, 1762, 7478, 2382, 2552, 4563, 4510, 2512, 4873,\n",
            "        7178,  671, 6956, 3187, 5464, 5635, 3353, 4510, 2512,  102,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "attention_masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  369 测试数据\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    # 测试数据\n",
        "    scontents, slabels = load_corpus('Dataset' + '/' + 'test.txt')\n",
        "    sinput_ids, sattention_masks=Datapro(scontents).datagen()\n",
        "\n",
        "sinput_ids = torch.cat(sinput_ids, dim=0)\n",
        "sattention_masks = torch.cat(sattention_masks, dim=0)\n",
        "slabels = torch.tensor(slabels)\n",
        "print('测试集 原句: ', scontents[0])\n",
        "print('Token IDs:', sinput_ids[0])\n",
        "print('attention_masks:', sattention_masks[0])\n",
        "test_dataset = TensorDataset(sinput_ids, sattention_masks, slabels)\n",
        "test_size = int( len(test_dataset))\n",
        "\n",
        "print('{:>5,} 测试数据'.format(test_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFzPvyy82Fks"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch_size = 32\n",
        "test_loader = DataLoader(\n",
        "            test_dataset, # 验证数据.\n",
        "            shuffle=False, # 打乱顺序\n",
        "            batch_size = batch_size\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SERlzbg22HMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a7bf95-e6f9-4d1e-8b7e-64495f880692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_rel_acc=0.8997289972899729\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mymodel.eval()\n",
        "f=open('prediction.csv','w',encoding='utf_8')\n",
        "f.write('{},{}\\n'.format('ID','label'))\n",
        "predictions=[]\n",
        "r_acc = 0\n",
        "with torch.no_grad():\n",
        "    for i,batch in enumerate(test_loader):\n",
        "        inputs_id, att_mask,rel_batch =batch\n",
        "        inputs_id, att_mask = inputs_id.to(device), att_mask.to(device)\n",
        "        pre=mymodel(inputs_id, att_mask)\n",
        "        rel_tar = rel_batch.to(device)\n",
        "        # rel_tar = rel_tar.unsqueeze(-1)\n",
        "        rel=torch.argmax(pre,1)\n",
        "        rel_acc = torch.eq(rel, rel_tar).sum().float().item()\n",
        "        r_acc += rel_acc\n",
        "        # pre=pre.squeeze(-1)\n",
        "        # predictions.extend(pre.ge(0.5).int().cpu().numpy().tolist())\n",
        "print('test_rel_acc={}'.format(r_acc/(len(test_dataset))))\n",
        "\n",
        "\n",
        "# for i, pre in enumerate(predictions):\n",
        "#     f.write('{},{}\\n'.format(i, pre))"
      ]
    }
  ]
}